Artificial disease progression model simulation
Algorithm was simple
* Deterime an nonlinear deterministic disease prgression model for the placebo group. Get treatment group by reducing the model by some percentage. 
* Plans to generated longitudinal data from the model for treated and palcebo group for 5 time points
* Generate Multivariate normal for each of the time point with mean 0, diseared variance and correlation matrix 
* Add the normal error to the deterministic model
* Run statistical models to see whether it can detect the desired difference between placebo and treatment

Learning: 
1. Each time the algorithm producing same estimate repeatedly. After a long investigation I realized, I set seed to null and solved the issue forever. For reproducibility, it would be better to use a series of random number seed for each iteration.
2. I am not sure why that solved the problem as this is the first time. However, microsoft co-pilot has some thought on it thought does not completely make sense. It took couple of day to find the solution.

"When you use set.seed(NULL), it initializes the random number generator with a seed based on the current time and process ID, which ensures that you get different random numbers 
each time you run your code1. This is why you observed different random numbers after using set.seed(NULL).
Without explicitly setting a seed, R uses the current state of the random number generator, which can sometimes result in the same sequence of random numbers 
if the state hasn't changed significantly between runs. By setting the seed to NULL, you force R to use a new, unpredictable seed each time, ensuring variability in the generated random numbers."

However the following make sense. I had been using the parallel processing frequently. 
The situation where R uses the current state of the random number generator (RNG) and produces the same sequence of random numbers can occur under specific conditions:
Short Time Intervals Between Runs: If you run your code multiple times in quick succession without setting a new seed, the RNG state might not change significantly. This can lead to the same sequence of random numbers being generated.
Parallel Processing: In parallel computations, if the RNG state is not properly managed, different nodes might end up using the same state, leading to identical sequences of random numbers. Proper partitioning or re-parametrization of the RNG is necessary to avoid this1.
Reproducibility: If you explicitly set a seed using set.seed() and then run your code, R will produce the same sequence of random numbers each time. This is useful for reproducibility but can lead to the same data being generated if the seed is not changed.
Finite State Space: The RNG in R has a finite state space, meaning that given enough random number generations, the sequences can eventually repeat. This is a rare occurrence but theoretically possible1.
Default RNG State: If you do not set a seed and the RNG state is not significantly altered by other operations, the default state might lead to similar sequences being generated in different runs.


Regarding LMER fit for the FTD simulation:
For simulating type 1 error with the natural cubic spline, the lmer model was used with the time basis function. In the random effect used 
(0 + Mcat|id). Mcat is the factor variable of discrete time point of (0, 6, 12, 18, 24) months. This is a longitudianl data and a subject was
observed at those time points. The random effects estimates 5 parameter for 5 observation which leads to overfit repeatedly. Hui thinks this is okay
However, this leads the warning of "Boundary Singular Fit". Here is the reason and consequence of boundary singular fit

Reasons:
Boundary Singular fit implies the varianace of estimates of randome effects are effectively zero. This might happen due to the following1. 
1. Multicollinearity
2. Overfitting
3. insufficient data

Consequence if we ignore this:
1. Random effect variance estimate zero implies the non-existance of the model
2. SE and CIs might be under estimated, that leads to over confidence inference.
3. This might inflates the type-1 error (false positive)
4. Poor generalization

Solution:
1. Simplify the model structure that require lower number of parameter to estimate
2. Increase sample size
3. Alternative modeling approace

Coding:
If we want to capture the error message or warnings for a method for an estimator, that should not be included within the function of the estimate
for example ncs2.fit in the FTD_sminulation repository.

